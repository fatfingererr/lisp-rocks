#+OPTIONS: toc:nil
#+BEGIN_SRC json :noexport:
{:title "Wittgenstein's Remarks on the Foundations of AI 第二章閱讀筆記" :layout :post :tags ["reading" "philosophy"] :toc false}
#+END_SRC
* 　


** 　

最近參與了本書 [[https://www.amazon.com/Wittgensteins-Remarks-Foundations-Stuart-Shanker/dp/0415408571][Wittgenstein's Remarks on the Foundations of AI]] 的哲學讀書會

所以想說把一些筆記重點紀錄下來，在第二章大量討論人工智慧與規範性之間的關係

不理解規範性是什麼的話，本文很有可能看不懂，請留意

<br>

** 拆解「學習」這個概念

圖靈認為更高層次的學習概念，也可以拆解成更簡單的一些小概念連貫起來

這邊談的概念（ concept ）其實是一種「刺激」與「反映」的聯繫關係

因為對於普通人來說，我們講 *X 具有 Y 概念* 其實往往是意味著 X 能做出某件關於 Y 概念的事情

也因此對於概念的掌握，其實是一種將概念視同一連串的等價反應（ equivaience response ）

<br>

舉例來說，一個主體 S 如果能適當地回應 Φ 如何使用，並且掌握 Φ 的規則以及解釋 Φ 是什麼

那這樣我們會說主體 S 學習了關於 Φ 的概念

然而對於人工智慧系統來說，在回應、掌握和解釋上面，可能受到嚴重的限制

因此對於人工智慧來說，我們不應該說這樣的系統學習了什麼概念，而是要換一個講法

我們與其說人工智慧「學習了 X」，我們可能可以說他「有條件做 X」

<br>

然而圖靈可能會認為，我們在思維上也很難區分這兩者，所以在行為上也很難分辨「學習了」和「有條件」的關係

真的很難區分嗎？實際上「有條件做」和「學習」之間有個因果關係程度上的差異

<br>

舉例來說，我們不一定要用因果關係的規範性術語，像是「有條件」這樣來描述學習

像是你學習說話，你很難說你從什麼時間點確切開始學習，觸發什麼條件才學習，然後到什麼時間點結束

但是掌握說話的相關概念是很重要的，也就是掌握說話的因果關係，在什麼樣前提條件下說什麼話

<br>

** 實踐的規範性：上升的複雜性

我們可以看到一個真正的「學習」案例，例如我們因為在學加法，學習了 1+1 = 2

然而這學習過程，會遮蔽掉我們去思考加法（+）的意思，這是因為我們要區分「加法」和「做加法」的差異

這種情況會造成「上升的複雜性」，在學習過程中為了區分，需要使用抽象概念暫時代替

也因此我們需要採取各種不同的規範實踐方法

使得我們最後把這個上升的複雜性的異質性降低到一個共同範式，也就是一個功能性的定義

<br>

然而在圖靈，或是現在的人工智慧系統中，並沒有去掌握這樣的規範性

透過把學習拆解成一連串小部分的連續概念，只會導致破壞「學習」這個概念依賴的規範性基礎

這大概就是 2-3 的重點。


<br>

** 機器可以學會閱讀嗎？

在 2-4 維根斯坦開始思考底下三者閱讀的差異：

1. 機械式地閱讀，想成人工智慧系統或機器的閱讀
2. 普通人在不瞭解詞語的情況下閱讀
3. 普通人正常的閱讀

維根斯坦指出，我們很難區分 2 和 3 ，例如政治家拿著演講稿照稿念、和小朋友正在開始學習閱讀

維根斯坦好奇的是 1 和 3 之間也有像似 2 和 3 之間的難以區分的情況嗎？

<br>

這邊比較機器閱讀和正常人閱讀，似乎只差在有沒有一個「意識」的感覺

看起來，機器和正常人都擁有「閱讀」的能力，都可以看著文章，然後機器可以烙印在他的狀態上面

而我們人可以將看到的視覺資訊透過神經系統轉換，然後透過大腦各種奇怪作用達到閱讀行為

看起來之間也有模糊地帶的樣子

<br>

然而維根斯坦更關心的事情是，在這種問題上面我們常常搞混「擁有（possession）」能力

和「行使（exercise）」能力之間的關係，前面那樣的定義，也緊緊是說明了「行使閱讀能力」層面的說明

但是對「擁有閱讀能力」層面，很明顯機器和人工智慧系統是有差異的

擁有閱讀能力更多的受到規範性影響，包含前面提到的「獲取知識」和「表現出像擁有知識」一樣
