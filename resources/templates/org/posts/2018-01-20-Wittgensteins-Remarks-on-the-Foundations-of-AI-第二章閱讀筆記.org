#+OPTIONS: toc:nil
#+BEGIN_SRC json :noexport:
{:title "Wittgenstein's Remarks on the Foundations of AI 第二章閱讀筆記" :layout :post :tags ["reading" "philosophy"] :toc false}
#+END_SRC
* 　


** 　

最近參與了本書 [[https://www.amazon.com/Wittgensteins-Remarks-Foundations-Stuart-Shanker/dp/0415408571][Wittgenstein's Remarks on the Foundations of AI]] 的哲學讀書會

所以想說把一些筆記重點紀錄下來，在第二章大量討論人工智慧與規範性之間的關係

不理解規範性是什麼的話，本文很有可能看不懂，請留意

<br>

** 拆解「學習」這個概念

圖靈認為更高層次的學習概念，也可以拆解成更簡單的一些小概念連貫起來

這邊談的概念（ concept ）其實是一種「刺激」與「反映」的聯繫關係

因為對於普通人來說，我們講 *X 具有 Y 概念* 其實往往是意味著 X 能做出某件關於 Y 概念的事情

也因此對於概念的掌握，其實是一種將概念視同一連串的等價反應（ equivaience response ）

<br>

舉例來說，一個主體 S 如果能適當地回應 Φ 如何使用，並且掌握 Φ 的規則以及解釋 Φ 是什麼

那這樣我們會說主體 S 學習了關於 Φ 的概念

然而對於人工智慧系統來說，在回應、掌握和解釋上面，可能受到嚴重的限制

因此對於人工智慧來說，我們不應該說這樣的系統學習了什麼概念，而是要換一個講法

我們與其說人工智慧「學習了 X」，我們可能可以說他「有條件做 X」

<br>

然而圖靈可能會認為，我們在思維上也很難區分這兩者，所以在行為上也很難分辨「學習了」和「有條件」的關係

真的很難區分嗎？實際上「有條件做」和「學習」之間有個因果關係程度上的差異

<br>

舉例來說，我們不一定要用因果關係的規範性術語，像是「有條件」這樣來描述學習

像是你學習說話，你很難說你從什麼時間點確切開始學習，觸發什麼條件才學習，然後到什麼時間點結束

但是掌握說話的相關概念是很重要的，也就是掌握說話的因果關係，在什麼樣前提條件下說什麼話

<br>

** 實踐的規範性：上升的複雜性

我們可以看到一個真正的「學習」案例，例如我們因為在學加法，學習了 1+1 = 2

然而這學習過程，會遮蔽掉我們去思考加法（+）的意思，這是因為我們要區分「加法」和「做加法」的差異

這種情況會造成「上升的複雜性」，為了區分只能使用更高層次的抽象描述

也因此我們需要採取各種不同的規範實踐方法

使得我們最後把這個上升的複雜性的異質性降低到一個共同範式，也就是一個功能性的定義

<br>

然而在圖靈，或是現在的人工智慧系統中，並沒有去掌握這樣的規範性

透過把學習拆解成一連串小部分的連續概念，只會導致破壞「學習」這個概念依賴的規範性基礎

這大概就是 2-3 的重點，可以濃縮成這句話：


> The continuum picture only serves to undermine the normative foundation on which the concept of learning rests.
